ğŸš€ ML Level 2 - Advanced Models (XGBoost, LightGBM, CatBoost)

A collection of high-performance machine learning models implemented in Python, focusing on gradient boosting techniques.






ğŸ“Œ Overview

This repository explores advanced machine learning models, focusing on gradient boosting techniques to solve classification and regression problems. Each model is implemented in Python and run in Google Colab.

ğŸ“‚ Project Structure

ML-Level-2/
â”œâ”€â”€ classification/
â”‚   â”œâ”€â”€ xgboost_classifier.ipynb
â”‚   â”œâ”€â”€ lightgbm_classifier.ipynb
â”‚   â”œâ”€â”€ catboost_classifier.ipynb
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ churn_modelling.csv
â”œâ”€â”€ regression/
â”‚   â”œâ”€â”€ xgboost_regressor.ipynb
â”‚   â”œâ”€â”€ lightgbm_regressor.ipynb
â”‚   â”œâ”€â”€ catboost_regressor.ipynb
â”‚   â”œâ”€â”€ regression_model_comparison.ipynb
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ insurance.csv
â”œâ”€â”€ README.md

ğŸ“š Models & Features

ğŸ”¹ Classification Models

âœ” XGBoost Classifier

âœ” LightGBM Classifier

âœ” CatBoost Classifier

ğŸ”¹ Regression Models

âœ” XGBoost Regressor

âœ” LightGBM Regressor

âœ” CatBoost Regressor

ğŸ”¹ Model Comparison

ğŸ“Š Side-by-side performance comparison

ğŸ“Œ Hyperparameter tuning insights

ğŸ“ˆ Visualization of model evaluation metrics

ğŸš€ Running the Models

1ï¸âƒ£ Setup Environment

Make sure you have the necessary libraries installed:

!pip install numpy pandas matplotlib seaborn scikit-learn xgboost lightgbm catboost

2ï¸âƒ£ Run Classification Models

# Example: Running XGBoost Classifier
from xgboost import XGBClassifier

model = XGBClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

3ï¸âƒ£ Run Regression Models

# Example: Running LightGBM Regressor
from lightgbm import LGBMRegressor

model = LGBMRegressor()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

ğŸ“Š Results & Insights

Model

Accuracy (Classification)

RMSE (Regression)

XGBoost

95.2%

4.57

LightGBM

94.8%

4.72

CatBoost

96.1%

4.49

ğŸš€ CatBoost showed the highest classification accuracy!ğŸ“‰ XGBoost performed best in regression!

ğŸ“œ License

This project is released under the MIT License. Feel free to use and modify the code.

ğŸ™Œ Acknowledgments

A huge thanks to Hadelin de Ponteves and Kirill Eremenko for their outstanding contributions to machine learning education! Their work in the SuperDataScience Machine Learning A-Z course has been invaluable in shaping this project. ğŸ‰

ğŸ”¥ Let's build powerful ML models together! If you find this repository useful, give it a â­ and fork it!

